---
draft: false 


date: 2024-04-25

categories:
  - RecSys Challenge 2024
  - Recommendation Systems
  - Exploratory Data Analysis
  - Data Science
---

!!! info "About"
    This year's challenge focuses on online news recommendation, addressing both the technical and normative challenges inherent in designing effective and responsible recommender systems for news publishing. The challenge will delve into the unique aspects of news recommendation, including modeling user preferences based on implicit behavior, accounting for the influence of the news agenda on user interests, and managing the rapid decay of news items. Furthermore, our challenge embraces the normative complexities, involving investigating the effects of recommender systems on the news flow and whether they resonate with editorial values. [[1]](https://recsys.eb.dk/)

!!! info "Challenge Task"
    The Ekstra Bladet RecSys Challenge aims to predict which article a user will click on from a list of articles that were seen during a specific impression. Utilizing the user's click history, session details (like time and device used), and personal metadata (including gender and age), along with a list of candidate news articles listed in an impression log, the challenge's objective is to rank the candidate articles based on the user's personal preferences. This involves developing models that encapsulate both the users and the articles through their content and the users' interests. The models are to estimate the likelihood of a user clicking on each article by evaluating the compatibility between the article's content and the user's preferences. The articles are ranked based on these likelihood scores, and the precision of these rankings is measured against the actual selections made by users. [[1]](https://recsys.eb.dk/)

!!! info note "Dataset Information"
    The Ekstra Bladet News Recommendation Dataset (EB-NeRD) was created to support advancements in news recommendation research. It was collected from user behavior logs at Ekstra Bladet. We collected behavior logs from active users during the 6 weeks from April 27 to June 8, 2023. This timeframe was selected to avoid major events, e.g., holidays or elections, that could trigger atypical behavior at Ekstra Bladet. The active users were defined as users who had at least 5 and at most 1,000 news click records in a three-week period from May 18 to June 8, 2023. To protect user privacy, every user was delinked from the production system when securely hashed into an anonymized ID using one-time salt mapping. Alongside, we provide Danish news articles published by Ekstra Bladet. Each article is enriched with textual context features such as title, abstract, body, categories, among others. Furthermore, we provide features that have been generated by proprietary models, including topics, named entity recognition (NER), and article embeddings. [[2]](https://recsys.eb.dk/dataset/)

    For more information on the [dataset](https://recsys.eb.dk/dataset/).

The purpose of this blog post is to go over the exploratory data analysis of this dataset. The post will be organized into the following sections:

- Data Preprocessing
- Functions
    * Plot Functions
    * Feature Functions
        * Article
        - User
        - Topic
        - Activity
- Feature Analysis
    - Overall Feature Analysis
    - Article
    - User
    - Session
    - Topic
    - Devices
    - Subscriber vs Non-Subscriber
    - Gender
    - Age
    - Postcodes


!!! note "Key Metrics" 
    We need to establish specific metrics and analyze how different features impact those metrics. Our platform generates revenue through both subscriptions and advertisements. User engagement is crucial because the more time users spend reading new articles, the greater our advertisement revenue.

# Data Preprocessing
Let's import our packages used for this section. 

```python
# Packages
from datetime import datetime
from plotly.subplots import make_subplots
import numpy as np
import pandas as pd
import plotly
import plotly.express as px
import plotly.graph_objects as go
```
Next, load in the three separate data sources of the dataset:

[**Articles**](https://recsys.eb.dk/dataset/#articles): Detailed information of news articles.

[**Behaviors**](https://recsys.eb.dk/dataset/#behaviors): Impression Logs. 

[**History**](https://recsys.eb.dk/dataset/#history): Click histories of users. 

```python
# Load in various dataframes
# Articles
df_art = pd.read_parquet("Data/Small/articles.parquet")

# Behaviors
df_bev = pd.read_parquet("Data/Small/train/behaviors.parquet")

# History
df_his = pd.read_parquet("Data/Small/train/history.parquet")
```
Now, how can we join these data sources together?

* **Articles** <> Article ID <> **Behavior**
* **History** <> User ID <> **Behavior**

Stop for now



